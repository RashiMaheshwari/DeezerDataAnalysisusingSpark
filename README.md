# Deezer Data Analysis using Spark

This project demonstrates how to build a scalable ETL pipeline for Deezer data analysis using Databricks Delta Live Tables (DLT), Spark, Delta Lake, and Azure Blob Storage. The pipeline is designed to handle raw data ingestion, incremental data loading, data transformation, and error handling.

## Project Overview

- **Objective**: Build an ETL pipeline to process and analyze Deezer data.
- **Tools & Technologies**: Databricks, Delta Live Tables (DLT), Spark, Delta Lake, PySpark, Azure Blob Storage.

## How to Run the Project
1. Upload the `deezer_dlt_pipeline.py` script to Databricks.
2. Configure your Azure Blob Storage connection in Databricks.
3. Run the Delta Live Tables pipeline.
4. Monitor the pipeline for data quality checks and performance.
